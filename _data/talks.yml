- name: Neural Networks for System Identification
  date: October 2024
  venue: Uppsala University @ Guest Lecture System identification
  type: invited university
  slides: https://docs.google.com/presentation/d/1af8cVyxCSc7njCJhx-mA_QJKYhRbVdfr-GG0Aqp9yDY/edit?usp=sharing
- name: Data-driven ECG analysis
  date: February 2024
  venue: Karolinska Institutet @ DDLS fellow public research seminars
  type: invited university

- name: Regularization properties of adversarially-trained linear regression
  date: December 2023
  venue: Conference on Neural Information Processing Systems (NeurIPS)
  type: conference
  slides: pdf/slides/2023-NeurIPS.pdf
  abstract: >-
    State-of-the-art machine learning models can be vulnerable to very small input perturbations that are
    adversarially constructed. Adversarial training is an effective approach to defend against it. Formulated
    as a min-max problem, it searches for the best solution when the training data were corrupted by the
    worst-case attacks. Linear models are among the simple models where vulnerabilities can be observed
    and are the focus of our study. In this case, adversarial training leads to a convex optimization problem
    which can be formulated as the minimization of a finite sum. We provide a comparative analysis between the
    solution of adversarial training in linear regression and other regularization methods. Our main findings
    are that: (A) Adversarial training yields the minimum-norm interpolating solution in the overparameterized
    regime (more parameters than data), as long as the maximum disturbance radius is smaller than a threshold.
    And, conversely, the minimum-norm interpolator is the solution to adversarial training with a given radius.
    (B) Adversarial training can be equivalent to parameter shrinking methods (ridge regression and Lasso). This
    happens in the underparametrized region, for an appropriate choice of adversarial radius and zero-mean
    symmetrically distributed covariates. (C) For $\ell_\infty$-adversarial training---as in square-root
    Lasso---the choice of adversarial radius for optimal bounds does not depend on the additive noise variance.
    We confirm our theoretical findings with numerical examples.


- name: Linear adversarial training, robustness in machine learning and applications to cardiology
  date: November 2023
  venue: Royal Institute of Technology, KTH, Sweden @ Division of Robotics, Perception and Learning
  type: invited university
  github: antonior92/Talk-KTH
  slides: pdf/slides/2023-KTH.pdf
  abstract: >-
    State-of-the-art machine learning models can be vulnerable to minimal input perturbations that are
    adversarially constructed. Adversarial training is an effective approach to defend against it. Formulated as a
    min-max problem, it searches for the best solution when worst-case attacks corrupt the training data. Linear
    models are among the simplest models where vulnerabilities can be observed and are the focus of our study. We
    provide a comparative analysis between the solution of adversarial training in linear regression and other
    regularization methods. We use this comparison to fully characterize adversarial training in linear regression.
    The results are used to characterize the tradeoffs between model size and adversarial robustness and motivated
    throughout the talk with examples of machine learning in cardiology, specifically applications where we use deep
    neural network models for the automatic diagnosis of the electrocardiogram.

- name: Ataques adversáriais em modelos lineares
  date: October, 2023
  venue: Laboratório Nacional de Computação Científica @ Petrópolis, RJ, Brazil (online)
  type: invited university
  slides: pdf/slides/2023-LNCC.pdf
  github: antonior92/LNCC-talk
  youtube: BpkB5IE5bms
  abstract: >-
    Modelos de aprendizado de máquina podem ser vulneráveis a perturbações de entrada muito pequenas construídas de
    forma adversárial. Examplos adversariais receberam muita atenção devido ao seu alto impacto no desempenho de
    modelos que, normalmente, produziriam resultados estado-da-arte. O treinamento adversárial é uma das abordagens
    mais eficazes para a defesa contra tais exemplos adversários e considera amostras perturbadas pelo adversário
    durante o treinamento para produzir modelos mais robustos. Nessa apresentação faremos uma análise comparativa
    entre a solução de treinamento adversárial em regressão linear e outros métodos de regularização. Há uma forte
    razão para esse foco: modelos de regressão linear permitem uma análise detalhada do problema. Além disso,
    muitos fenômenos interessantes observados em modelos não lineares ainda estão presentes e podem ser melhor
    entendidos. Por exemplo, a configuração pode usada para estudar como a alta dimensionalidade pode ser uma
    fonte adicional de robustez ou fragilidade para modelos. O método também possui propriedades favoráveis que
    permitem seu uso como um método básico para a estimar de modelos lineares.


- name: Robustness in large-scale machine learning and its relevance to AI-enabled ECG
  date: July, 2023
  venue: Imperial College, UK @ Imperial Centre for Translational and Experimental Medicine
  type: invited university
  slide: pdfs/slides/2023-ImperialCollege.pdf
- name: The Three Challenges of Using Deep Neural Networks in Electrocardiography
  date: May, 2023
  venue: IEEE EMBS @ Germany Chapter, Göttingen (online)
  github: antonior92/IEEE-EMBS-talk
  type: invited university
  slide: pdfs/slides/2023-IEEE-EMBS.pdf
- name: Revisitando o princípio da parcimônia na identificação de sistemas e aprendizado de máquina
  date: May, 2023
  venue: PUC Rio, Brazil @ Department of Mechanical Engineering
  github: antonior92/talk-PucRio
  type: invited university
  slide: pdfs/slides/2023-PUCRio.pdf
  abstract: >-
    As áreas de identificação de sistemas e o aprendizado de máquina visam construir modelos matemáticos a partir de
    dados. Tradicionalmente, a escolha da família de modelos a ser considerada exige do designer um equilíbrio entre
    dois objetivos de natureza conflitante; esta deve ser ser flexível o suficiente para capturar a dinâmica do sistema,
    mas não tão flexível que aprenda efeitos espúrios a partir conjunto de dados. No entanto, a boa performance de
    famílias de modelos com grande flexibilidade, como redes neurais profundas, levaram a uma revisão desse paradigma.
    Nessa apresentação discutiremos os fenômenos de "double-descent" e de "benign-overfitting" que ajudam a interpretar
    essas idéias. Com especial foco em dois casos de interesse: sistemas dinâmicos e ataques adversáriais (para os quais
    a entrada do sistema é contaminada com perturbações selecionadas de forma a fazer o sistema fazer predições errôneas).
  publications:
    - ribeiro_overparameterized_2023
    - ribeiro_surprises_2022
    - ribeiro_occam_2021b
    - pillonetto_deep_2023
- name: Overparametrized linear regression under adversarial attacks
  date: March, 2023
  venue: INRIA Paris, France @ SIERRA team
  slide: pdfs/slides/2023-Inria.pdf
  type: invited university
  abstract: >-
    State-of-the-art machine learning models can be vulnerable to very small input perturbations that are adversarially
    constructed. Adversarial attacks are a popular framework for studying these vulnerabilities. They consider worst-case
    input disturbances designed to maximize model error and got a lot of attention due to their impact on the performance
    of state-of-the-art models. Adversarial training considers extending model training with these examples and is an
    effective approach to defend against such attacks. This talk will explore adversarial attacks and training in linear
    regression. There is a strong reason for this focus, for linear regression, adversarial training can be formulated
    as a convex and quadratic problem. Moreover, many interesting phenomena that can be observed in nonlinear models are
    still present. The setup is used to study the relationship between high dimensionality and robustness. And to reveal
    the connection between adversarial training, parameter-shrinking methods, and minimum-norm solutions.

- name:  Adversarially-trained linear regression
  date: November 2022
  venue: Uppsala University, Sweden @ System and Control Division (Microseminar)
  github: antonior92/microseminar
  type: local
  slide: pdfs/slides/2022-microseminar.pdf
  publications:
    - ribeiro_overparameterized_2023
    - ribeiro_surprises_2022
- name: Adversarial Attacks in Linear Regression
  venue: Seminars on Advances in Probabilistic Machine Learning @ Aalto University and ELLIS unit Helsinki
  date: November 2022
  type: invited university
  slide: pdfs/slides/2022-APML.pdf
  website: https://aaltoml.github.io/apml/
  abstract:  >-
    State-of-the-art machine learning models can be vulnerable to very small input perturbations that are
    adversarially constructed. Adversarial attacks are a popular framework for studying these vulnerabilities.
    They consider worst-case input disturbances designed to maximize model error and got a lot of attention due
    to their impact on the performance of state-of-the-art models. Adversarial training considers extending model
    training with these examples and is an effective approach to defend against such attacks. This talk will explore
    adversarial attacks and training in linear regression.  There is a strong reason for this focus, for linear
    regression, adversarial training can be formulated as a convex and quadratic problem. Moreover, many interesting
    phenomena that can be observed in nonlinear models are still present. The setup is used to study the role of high
    dimensionality in robustness. And to reveal the connection between adversarial training, parameter-shrinking methods
    and minimum-norm solutions.
  publications:
    - ribeiro_overparameterized_2023
    - ribeiro_surprises_2022
- name: Learning signals and systems and its applications to electrocardiography
  venue: Aalto University, Finland @ Jobtalk (Online)
  date: June 2022
  slide: pdfs/slides/2022-JobtalkAalto.pdf
  github: antonior92/talk-ubc
  type: jobtalk
  publications:
    - ribeiro_automatic_2020a
    - gustafsson_artificial_2021
    - ribeiro_overparameterized_2023
- name: Overparameterized Linear Regression under Adversarial Attacks
  venue: University of British Columbia, Canada @ Christos Thrampoulidis group (Online)
  date: June 2022
  slide: pdfs/slides/2022-UBC.pdf
  github: antonior92/talk-ubc
  type: invited university
  abstract:  >-
      State-of-the-art machine learning models can be vulnerable to very small input perturbations that are
      adversarially constructed. Adversarial attacks are a popular framework for studying these vulnerabilities and got
      a lot of attention due to their high impact on deep neural network performance. Adversarial training is one of the
      most effective approaches to defending against such adversarial examples and considers adversarially perturbed samples
      during training to produce more robust models. This talk will explore adversarial attacks and training in a simpler
      setting than it is usually studied, linear regression.  There is a strong reason for this focus, for linear regression
      models adversarial training can be simplified into a convex and quadratic form. Moreover, a lot of interesting
      phenomena that can still be observed in nonlinear models are still present. The setup is used to study how
      high-dimensionality can be either a source of additional robustness or brittleness.  And also to show, in
      the linear setting, similarities (and differences) between $\ell_\infty$-adversarial training and the lasso
      and between $\ell_2$-adversarial training and ridge regression.
  publications:
    - ribeiro_overparameterized_2023
    - ribeiro_surprises_2022
- name: Deep Neural Networks for Automatic ECG Analysis
  venue:  University of Luxembourg @ Systems Control Group, LCSB (Online)
  date: March 2022
  slide: pdfs/slides/2022-UniLux.pdf
  github: antonior92/presentation-lux
  type: invited university
  publications:
    - ribeiro_automatic_2020a
    - lima_deep_2021
    - gustafsson_artificial_2021
    - biton_atrial_2021
    - ribeiro_overparameterized_2023
- name: On the robustness of overparametrized models
  venue: Uppsala University, Sweden @ System and Control Division (Microseminar)
  date: Nov. 2021
  slide: pdfs/slides/2021-Microseminar.pdf
  github: antonior92/micro-seminar
  type: local
  publications:
    - ribeiro_overparametrized_2021
    - ribeiro_occam_2021b
- name: Aprendendo modelos para sinais e sistemas
  youtube: CSjBICRX8_o
  venue: Premio UFMG de Teses
  date: Oct. 2021
  slide: pdfs/slides/2021-PremioTeses.pdf
  github: antonior92/premio-teses
  type: local
  publications:
    - ribeiro_learning_2020
- name: "Beyond Occam's Razor in System Identification: Double-Descent when Modeling Dynamics"
  slide: pdfs/slides/2021-SYSID.pdf
  venue: "19th IFAC symposium on System Identification: learning models for decision and control"
  date: July 2021
  website: https://www.sysid2021.org/
  type: conference
  publications:
    - ribeiro_occam_2021b
- name: How convolutional neural networks deal with aliasing
  slide: pdfs/slides/2021-ICASSP.pdf
  venue: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)
  date: June 2021
  website: https://www.2021.ieeeicassp.org/
  type: conference
  publications:
    - ribeiro_how_2021
- name: Overparametrized Regression Under L2 Adversarial Attacks
  youtube: lznrSfbxJyE?start=498
  venue: Workshop on the Theory of Overparameterized Machine Learning
  website: https://topml.rice.edu/
  date: April 2021
  slide: pdfs/slides/2021-TOPML.pdf
  type: workshop
  publications:
    - ribeiro_overparametrized_2021
- name: Artificial intelligence for ECG classifcation and prediction of the risk of death
  slide: pdfs/slides/2021-ICE.pdf
  youtube: zoIbT4VUH9c?mute=1
  venue: International Congress on Electrocardiology (Online)
  website: https://ice2021.pl/
  date: April 2021
  type: invited conference
  publications:
      - lima_deep_2021
      - ribeiro_automatic_2020
- name: Artificial intelligence for ECG classification and prediction of the risk of death
  slide: pdfs/slides/2021-AIMLab.pdf
  venue: Techinion, Israel @  AIMLab group (Online)
  date: March 2021
  website: https://aim-lab.github.io/
  type: invited university
  publications:
    - lima_deep_2021
    - ribeiro_automatic_2020
- name: "Beyond exploding and vanishing gradients: analysing RNN training using attractors and smoothness"
  slidelive: 38930165
  venue: International Conference On Artificial Intelligence And Statistics (AISTATS)
  date: 2020
  type: conference
  publications:
    - ribeiro_exploding_2020
